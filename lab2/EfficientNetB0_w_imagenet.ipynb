{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "EfficientNetB0_w/resnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzRBJGi4yl2G",
        "outputId": "d3998ee8-6b55-438a-d45b-2382e3a8b055"
      },
      "source": [
        "%tensorflow_version 2.x\r\n",
        "import tensorflow as tf\r\n",
        "device_name = tf.test.gpu_device_name()\r\n",
        "if device_name != '/device:GPU:0':\r\n",
        "  raise SystemError('GPU device not found')\r\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "rn2WfOT3X__R"
      },
      "source": [
        "!pip install opendatasets --upgrade --quiet\n",
        "import opendatasets as od\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpE_31wIX__b",
        "outputId": "536f6e46-5c05-43cd-89ff-6a12fb815249"
      },
      "source": [
        "dataset_url = 'https://www.kaggle.com/virtualdvid/oregon-wildlife'\n",
        "od.download(dataset_url)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: wastex\n",
            "Your Kaggle Key: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0.00/4.55G [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading oregon-wildlife.zip to ./oregon-wildlife\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.55G/4.55G [01:30<00:00, 54.1MB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xz3iRTRjX__d",
        "outputId": "b10a52e1-65f0-4208-bf09-7304705cc8d1"
      },
      "source": [
        "data_dir = './oregon-wildlife/oregon_wildlife/oregon_wildlife'\n",
        "print(os.listdir(data_dir))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['columbian_black-tailed_deer', 'bald_eagle', 'coyote', 'cougar', 'black_bear', 'elk', 'sea_lions', 'raven', 'seals', 'bobcat', 'gray_fox', 'red_fox', 'raccoon', 'canada_lynx', 'mountain_beaver', 'deer', 'nutria', 'ringtail', 'gray_wolf', 'virginia_opossum']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5kVRv4RpX__d"
      },
      "source": [
        "os.makedirs('./logs')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_vS4VR2MX__e"
      },
      "source": [
        "def clear_data(root):\n",
        "    for folder_name in os.listdir(root):\n",
        "        for file_name in os.listdir(root+'/'+folder_name):\n",
        "            base_name, ext = os.path.splitext(file_name)\n",
        "            if ext != '.jpg':\n",
        "                os.remove(root+'/'+folder_name+'/'+file_name)\n",
        "clear_data(data_dir)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PYCSxMt8X__f"
      },
      "source": [
        "log_dir = './logs'\n",
        "batch_size = 128\n",
        "img_size = 224\n",
        "num_classes = 20"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh7dhkXdX__f",
        "outputId": "d3370b93-2f5f-450f-99ab-f934f8d360a9"
      },
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(data_dir, labels='inferred',\n",
        "            color_mode='rgb', batch_size=batch_size, image_size=(img_size, img_size),\n",
        "            shuffle=True, seed=41, validation_split=0.3, subset='training')\n",
        "valid_ds = tf.keras.preprocessing.image_dataset_from_directory(data_dir, labels='inferred',\n",
        "            color_mode='rgb', batch_size=batch_size, image_size=(img_size, img_size),\n",
        "            shuffle=True, seed=41, validation_split=0.3, subset='validation')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 12786 files belonging to 20 classes.\n",
            "Using 8951 files for training.\n",
            "Found 12786 files belonging to 20 classes.\n",
            "Using 3835 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "b9A49OzmX__g"
      },
      "source": [
        "def input_preprocess(image, label):\n",
        "    label = tf.one_hot(label, num_classes)\n",
        "    return image, label\n",
        "\n",
        "\n",
        "train_ds = train_ds.map(\n",
        "    input_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        ")\n",
        "train_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "valid_ds = valid_ds.map(input_preprocess)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1jdOP1ZhX__h"
      },
      "source": [
        "def build_model():\n",
        "    inputs = tf.keras.Input(shape=(img_size, img_size, 3))\n",
        "    model = tf.keras.applications.EfficientNetB0(input_tensor=inputs, include_top=False, weights=\"imagenet\")\n",
        "    model.trainable = False\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(model.output)\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation=tf.keras.activations.softmax)(x)\n",
        "    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
        "    model.compile(\n",
        "        optimizer=tf.optimizers.Adam(0.001),\n",
        "        loss=tf.keras.losses.categorical_crossentropy,\n",
        "        metrics=[tf.keras.metrics.categorical_accuracy],\n",
        "    )\n",
        "    return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bsdT5NIX__i",
        "outputId": "b15a4452-133d-4a22-c2fe-b342b980c63c"
      },
      "source": [
        "model = build_model()\n",
        "    \n",
        "model.fit(\n",
        "    train_ds,\n",
        "    epochs=50,\n",
        "    validation_data=valid_ds,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.TensorBoard(log_dir),\n",
        "    ]\n",
        "  )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n",
            "Epoch 1/50\n",
            "70/70 [==============================] - 207s 2s/step - loss: 1.9366 - categorical_accuracy: 0.5076 - val_loss: 0.6129 - val_categorical_accuracy: 0.8412\n",
            "Epoch 2/50\n",
            "70/70 [==============================] - 173s 2s/step - loss: 0.5794 - categorical_accuracy: 0.8506 - val_loss: 0.4553 - val_categorical_accuracy: 0.8683\n",
            "Epoch 3/50\n",
            "70/70 [==============================] - 141s 2s/step - loss: 0.4399 - categorical_accuracy: 0.8756 - val_loss: 0.3943 - val_categorical_accuracy: 0.8855\n",
            "Epoch 4/50\n",
            "70/70 [==============================] - 131s 2s/step - loss: 0.3753 - categorical_accuracy: 0.8991 - val_loss: 0.3585 - val_categorical_accuracy: 0.8941\n",
            "Epoch 5/50\n",
            "70/70 [==============================] - 132s 2s/step - loss: 0.3261 - categorical_accuracy: 0.9077 - val_loss: 0.3337 - val_categorical_accuracy: 0.8993\n",
            "Epoch 6/50\n",
            "70/70 [==============================] - 132s 2s/step - loss: 0.3019 - categorical_accuracy: 0.9149 - val_loss: 0.3141 - val_categorical_accuracy: 0.9017\n",
            "Epoch 7/50\n",
            "70/70 [==============================] - 132s 2s/step - loss: 0.2711 - categorical_accuracy: 0.9230 - val_loss: 0.2997 - val_categorical_accuracy: 0.9056\n",
            "Epoch 8/50\n",
            "70/70 [==============================] - 131s 2s/step - loss: 0.2500 - categorical_accuracy: 0.9338 - val_loss: 0.2883 - val_categorical_accuracy: 0.9074\n",
            "Epoch 9/50\n",
            "70/70 [==============================] - 131s 2s/step - loss: 0.2293 - categorical_accuracy: 0.9380 - val_loss: 0.2771 - val_categorical_accuracy: 0.9113\n",
            "Epoch 10/50\n",
            "70/70 [==============================] - 131s 2s/step - loss: 0.2149 - categorical_accuracy: 0.9418 - val_loss: 0.2690 - val_categorical_accuracy: 0.9150\n",
            "Epoch 11/50\n",
            "70/70 [==============================] - 131s 2s/step - loss: 0.1958 - categorical_accuracy: 0.9479 - val_loss: 0.2609 - val_categorical_accuracy: 0.9194\n",
            "Epoch 12/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.1925 - categorical_accuracy: 0.9508 - val_loss: 0.2547 - val_categorical_accuracy: 0.9218\n",
            "Epoch 13/50\n",
            "70/70 [==============================] - 131s 2s/step - loss: 0.1756 - categorical_accuracy: 0.9560 - val_loss: 0.2490 - val_categorical_accuracy: 0.9241\n",
            "Epoch 14/50\n",
            "70/70 [==============================] - 133s 2s/step - loss: 0.1712 - categorical_accuracy: 0.9539 - val_loss: 0.2437 - val_categorical_accuracy: 0.9257\n",
            "Epoch 15/50\n",
            "70/70 [==============================] - 132s 2s/step - loss: 0.1568 - categorical_accuracy: 0.9619 - val_loss: 0.2389 - val_categorical_accuracy: 0.9239\n",
            "Epoch 16/50\n",
            "70/70 [==============================] - 131s 2s/step - loss: 0.1549 - categorical_accuracy: 0.9604 - val_loss: 0.2348 - val_categorical_accuracy: 0.9265\n",
            "Epoch 17/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.1480 - categorical_accuracy: 0.9630 - val_loss: 0.2311 - val_categorical_accuracy: 0.9288\n",
            "Epoch 18/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.1347 - categorical_accuracy: 0.9678 - val_loss: 0.2282 - val_categorical_accuracy: 0.9293\n",
            "Epoch 19/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.1425 - categorical_accuracy: 0.9655 - val_loss: 0.2245 - val_categorical_accuracy: 0.9314\n",
            "Epoch 20/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.1269 - categorical_accuracy: 0.9739 - val_loss: 0.2230 - val_categorical_accuracy: 0.9319\n",
            "Epoch 21/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.1183 - categorical_accuracy: 0.9723 - val_loss: 0.2195 - val_categorical_accuracy: 0.9353\n",
            "Epoch 22/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.1192 - categorical_accuracy: 0.9741 - val_loss: 0.2163 - val_categorical_accuracy: 0.9335\n",
            "Epoch 23/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.1187 - categorical_accuracy: 0.9708 - val_loss: 0.2155 - val_categorical_accuracy: 0.9364\n",
            "Epoch 24/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.1084 - categorical_accuracy: 0.9743 - val_loss: 0.2130 - val_categorical_accuracy: 0.9364\n",
            "Epoch 25/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.1065 - categorical_accuracy: 0.9755 - val_loss: 0.2119 - val_categorical_accuracy: 0.9369\n",
            "Epoch 26/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.1003 - categorical_accuracy: 0.9769 - val_loss: 0.2094 - val_categorical_accuracy: 0.9387\n",
            "Epoch 27/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.0955 - categorical_accuracy: 0.9815 - val_loss: 0.2080 - val_categorical_accuracy: 0.9366\n",
            "Epoch 28/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.0939 - categorical_accuracy: 0.9793 - val_loss: 0.2066 - val_categorical_accuracy: 0.9392\n",
            "Epoch 29/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.0914 - categorical_accuracy: 0.9784 - val_loss: 0.2046 - val_categorical_accuracy: 0.9377\n",
            "Epoch 30/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.0880 - categorical_accuracy: 0.9805 - val_loss: 0.2060 - val_categorical_accuracy: 0.9374\n",
            "Epoch 31/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.0854 - categorical_accuracy: 0.9818 - val_loss: 0.2049 - val_categorical_accuracy: 0.9377\n",
            "Epoch 32/50\n",
            "70/70 [==============================] - 131s 2s/step - loss: 0.0831 - categorical_accuracy: 0.9828 - val_loss: 0.2029 - val_categorical_accuracy: 0.9387\n",
            "Epoch 33/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.0827 - categorical_accuracy: 0.9841 - val_loss: 0.2017 - val_categorical_accuracy: 0.9413\n",
            "Epoch 34/50\n",
            "70/70 [==============================] - 131s 2s/step - loss: 0.0791 - categorical_accuracy: 0.9842 - val_loss: 0.2018 - val_categorical_accuracy: 0.9403\n",
            "Epoch 35/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.0758 - categorical_accuracy: 0.9845 - val_loss: 0.1998 - val_categorical_accuracy: 0.9400\n",
            "Epoch 36/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.0764 - categorical_accuracy: 0.9855 - val_loss: 0.1993 - val_categorical_accuracy: 0.9405\n",
            "Epoch 37/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.0738 - categorical_accuracy: 0.9826 - val_loss: 0.1991 - val_categorical_accuracy: 0.9403\n",
            "Epoch 38/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.0716 - categorical_accuracy: 0.9852 - val_loss: 0.1994 - val_categorical_accuracy: 0.9416\n",
            "Epoch 39/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.0697 - categorical_accuracy: 0.9850 - val_loss: 0.1982 - val_categorical_accuracy: 0.9426\n",
            "Epoch 40/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.0651 - categorical_accuracy: 0.9873 - val_loss: 0.1978 - val_categorical_accuracy: 0.9432\n",
            "Epoch 41/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.0649 - categorical_accuracy: 0.9862 - val_loss: 0.1972 - val_categorical_accuracy: 0.9439\n",
            "Epoch 42/50\n",
            "70/70 [==============================] - 131s 2s/step - loss: 0.0702 - categorical_accuracy: 0.9855 - val_loss: 0.1954 - val_categorical_accuracy: 0.9450\n",
            "Epoch 43/50\n",
            "70/70 [==============================] - 131s 2s/step - loss: 0.0660 - categorical_accuracy: 0.9864 - val_loss: 0.1945 - val_categorical_accuracy: 0.9437\n",
            "Epoch 44/50\n",
            "70/70 [==============================] - 131s 2s/step - loss: 0.0611 - categorical_accuracy: 0.9882 - val_loss: 0.1951 - val_categorical_accuracy: 0.9460\n",
            "Epoch 45/50\n",
            "70/70 [==============================] - 131s 2s/step - loss: 0.0577 - categorical_accuracy: 0.9896 - val_loss: 0.1946 - val_categorical_accuracy: 0.9447\n",
            "Epoch 46/50\n",
            "70/70 [==============================] - 131s 2s/step - loss: 0.0593 - categorical_accuracy: 0.9862 - val_loss: 0.1955 - val_categorical_accuracy: 0.9424\n",
            "Epoch 47/50\n",
            "70/70 [==============================] - 131s 2s/step - loss: 0.0571 - categorical_accuracy: 0.9900 - val_loss: 0.1937 - val_categorical_accuracy: 0.9465\n",
            "Epoch 48/50\n",
            "70/70 [==============================] - 131s 2s/step - loss: 0.0537 - categorical_accuracy: 0.9906 - val_loss: 0.1941 - val_categorical_accuracy: 0.9434\n",
            "Epoch 49/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.0559 - categorical_accuracy: 0.9897 - val_loss: 0.1945 - val_categorical_accuracy: 0.9458\n",
            "Epoch 50/50\n",
            "70/70 [==============================] - 130s 2s/step - loss: 0.0550 - categorical_accuracy: 0.9881 - val_loss: 0.1950 - val_categorical_accuracy: 0.9437\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "R6L5l47YX__i"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}